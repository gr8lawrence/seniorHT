---
title: "Classification Performance Visualization"
author: "Tianyi Liu"
date: "2/19/2019"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(pROC)
```

```{r load_data, include = FALSE}
data_path <- "/Users/gr8lawrence/Desktop/Senior Honors Thesis/R_output_from_cluster/"

fr <- list()

load(paste(data_path, "learning_result_RT_rf.Rdata", sep = ""))
fr[[1]] <- final_results

load(paste(data_path, "learning_result_RT_svm.Rdata", sep = ""))
fr[[2]] <- final_results

load(paste(data_path, "learning_result_TSPs_rf_tp_100.Rdata", sep = ""))
fr[[3]] <- final_results

load(paste(data_path, "learning_result_TSPs_svm_tp_500.Rdata", sep = ""))
fr[[4]] <- final_results
```

## Overview

In this document, we present visualizations of our results that demonstrate the performances of various combinations of data processing, learning strategy, and machine learning models. 

### Data Processing

In this section, we process our data and combine everything in a giant tibble file so that downstream tasks of plotting the data would be a lot easier. We have already loaded the data from runs on the clusters and only need to rearrange them now. The `tibble` below presents the final arrangement.

```{r data_processing, echo = FALSE}
results_tibble_list <- list()
results_tibble <- tibble() # This is the final giant tibble

for (i in c(2, 4)) {
  fr[[i]]$results <- fr[[i]]$results[ ,-c(3, 4)]
  colnames(fr[[i]]$results)[1:2] <- c("training.set", "test.set")
  fr[[i]]$results <- fr[[i]]$results %>% add_column(strategy = "Single") 
  for (j in 1:dim(fr[[i]]$results)[1]) {
    if (substr(fr[[i]]$results$training.set[j], 1, 4) == "comb" || substr(fr[[i]]$results$training.set[j], 1, 4) == "Comb" ) {
      fr[[i]]$results$training.set[j] <- "Combined"
      fr[[i]]$results$strategy[j] <- "Combined"
    } 
  }
  if (i == 2) {
    results_tibble_list[[i]] <- fr[[i]]$results %>% mutate(method = "SVM", transformation = "Rank")
  } else {
    results_tibble_list[[i]] <- fr[[i]]$results %>% mutate(method = "SVM", transformation = "TSPs")
  }
}


for (i in c(1, 3)) {
  colnames(fr[[i]]$results)[1:2] <- c("training.set", "test.set")
  fr[[i]]$results <- fr[[i]]$results %>% add_column(strategy = "Single") 
  for (j in 1:dim(fr[[i]]$results)[1]) {
    if (substr(fr[[i]]$results$training.set[j], 1, 4) == "comb" || substr(fr[[i]]$results$training.set[j], 1, 4) == "Comb" ) {
      fr[[i]]$results$training.set[j] <- "Combined"
      fr[[i]]$results$strategy[j] <- "Combined"
    } 
  }
  if (i == 1) {
    results_tibble_list[[i]] <- fr[[i]]$results %>% mutate(method = "RF", transformation = "Rank")
  } else {
    results_tibble_list[[i]] <- fr[[i]]$results %>% mutate(method = "RF", transformation = "TSPs")
  }
}


results_tibble <- rbind(results_tibble_list[[1]], results_tibble_list[[2]], results_tibble_list[[3]], results_tibble_list[[4]])

results_tibble <- results_tibble[order(results_tibble$transformation), ]  
results_tibble$accuracy <- as.numeric(results_tibble$accuracy)
results_tibble$sensitivity <- as.numeric(results_tibble$sensitivity)
results_tibble$specificity <- as.numeric(results_tibble$specificity)
results_tibble$method <- factor(results_tibble$method, levels = c("PLR", "RF", "SVM", "MTL"))
results_tibble$transformation <- factor(results_tibble$transformation, levels = c("Rank", "TSPs"))
results_tibble$strategy <- factor(results_tibble$strategy, levels = c("Single", "Combined"))

## We average the measurements of performance across results from "Single" dataset learning.
summary_table <- aggregate(cbind(accuracy, sensitivity, specificity) ~ test.set + method + transformation + strategy, data = results_tibble, mean)

print(as.tibble(summary_table, n = 10))
```

### Prediction Accuracy

One measurement of performances for any machine learning program is the prediction accuracy. Here, we present the boxplots for the accuracies of several of our combinations of data transformation methods, learning methods, and  learning strategies.

#### Figure 1 

```{r pred_accu}
ggplot(data = summary_table, aes(x = transformation, y = accuracy, fill = transformation)) +
  geom_boxplot(alpha = 0.8, width = 0.45) +
  ggtitle("Comparison of Prediction Accuracy") +
  xlab("Transformation") +
  ylab("Accuracy") +
  theme_light() + facet_grid(strategy ~ method) +
  theme(axis.text.x = element_text(vjust = 0.5)) +
  scale_fill_manual(values = c("#E69F00", "#56B4E9"), 
                    name = "Transformation")
```

### ROC Plot

Another way to visualize the performance of each program is to draw ROC curves. Because we know from the accuracy plot that random forest plus TSPs produces the best prediction accuracy, we will plot out the roc curves only for this combination under each learning cycle (from different datasets). The ROC curves are plotted using the `pROC` package. 

#### Preprocessing

We need to obtain the truth vectors before proceeding. 

``` {r data_pp2, echo = FALSE}
dataPath <- "/Users/gr8lawrence/Desktop/Senior Honors Thesis/datasets/" # The name of the directory where all data sets are stored locally
studies_names <- c("Aguirre-Seq", "Linehan-Seq", "COMPASS", "Moffitt Arrays", "TCGA-PAAD") # Names of the studies in the same order as being loaded
# Load datasets
load(paste(dataPath, "Aguirre_seq_plus.RData", sep = ""))
load(paste(dataPath, "Linehan_Seq_plus.RData", sep = ""))
load(paste(dataPath, "COMPASS.2017_plus.RData", sep = ""))
load(paste(dataPath, "Moffitt_GEO_array_plus.RData", sep = ""))
load(paste(dataPath, "TCGA_PAAD_plus.RData", sep = ""))
# Incorporate all datasets into a single list object
studies_df <- list(Aguirre_seq_plus, Linehan_Seq_plus, COMPASS.2017_plus, Moffitt_GEO_array_plus, TCGA_PAAD_plus)
num_studies <- length(studies_df) # Number of datasets

## Assign a truth vector to each cycle of learning using the loop below
truth_list <- list() # A list object to hold all truth vectors
for (i in 1:num_studies) {
  truth <- studies_df[[i]]$sampInfo$cluster.MT[!is.na(studies_df[[i]]$sampInfo$cluster.MT)] 
  for (j in 1:num_studies) {
    truth_list[[(i - 1) * num_studies + j]] <- truth
  }
}


## Below the predicitons from trainings on single and combined datasets were grouped and combined respectively
load(paste(data_path, "TSPs_rf_predictions.Rdata", sep = ""))
prediction_vec_single <- vector()
truth_vec_single <- vector()
prediction_vec_combined <- vector()
truth_vec_combined <- vector()
for (i in 1:num_studies^2) {
  if (i %% 5 != 0) {
    prediction_vec_single <- c(prediction_vec_single, final_preds[[i]]$predictions[,1]) 
    truth_vec_single <- c(truth_vec_single, truth_list[[i]])
  } else {
    prediction_vec_combined <- c(prediction_vec_combined, final_preds[[i]]$predictions[,1])
    truth_vec_combined <- c(truth_vec_combined, truth_list[[i]])
  }
}
truth_vec_single <- factor(ifelse(truth_vec_single == 1, "basal", "classical"), levels = c("basal", "classical"))
truth_vec_combined <- factor(ifelse(truth_vec_combined == 1, "basal", "classical"), levels = c("basal", "classical"))
```
#### Figure 2

```{r roc_curve}
roc1 <- plot.roc(truth_vec_single,prediction_vec_single, 
         main = "ROC Curves for Predictions \nRandom Forest + TSPs",
         cex.main = 1.05,
         #smooth = TRUE,
         ci = TRUE,
         col = "#E69F00")
lineobj <- lines.roc(truth_vec_combined, prediction_vec_combined,
                     #smooth = TRUE,
                     ci = TRUE,
                     col = "#56B4E9")
legend("bottomright", legend = c("Single", "Combined"), col = c("#E69F00", "#56B4E9"), lwd = 2, title = "Strategy")
```

### MTL
Multitask learning (MTL) is a relatively new machine learning technique for classification that weighs in the information from all datasets for training in addition to that of each single dataset. In our study, we apply an implementation of the MTL as an analougue to the penalized logistic regression (with a specific L21 norm) with extra penalization for leveraging across-dataset information to predict pancreatic cancer subtypes from genomic data. 

As shown above, random forest plus TSPs shows the most promisiong results among all the strategies withouth using the MTL. In this section, we evaluate the performance of using the MTL method alongside random forest plus TSPs to see if the new technique brings improvement to the predictions of pancreateic cancer subtypes.

``` {r mtl_data_processing, echo = FALSE}
## Load the MTL results from the cluster
load(paste(data_path, "MTL_RT_results.RData", sep = ""))
load(paste(data_path, "MTL_RT_predictions.RData", sep = ""))
mtl_rt_results <- final_results$results
mtl_rt_results_trans <- add_column(mtl_rt_results, method = "MTL", transformation = "Rank")
mtl_rt_models <- final_results$models
mtl_rt_preds <- final_preds
load(paste(data_path, "MTL_TSPs_results.RData", sep = ""))
load(paste(data_path, "MTL_TSPs_predictions.RData", sep = ""))
mtl_tsps_results <- final_results$results
mtl_tsps_results_trans <- add_column(mtl_tsps_results, method = "MTL", transformation = "TSPs")
mtl_tsps_models <- final_results$models
mtl_tsps_preds <- final_preds

## Combine the learning results into one dataset
mtl_results <- rbind(mtl_rt_results_trans, mtl_tsps_results_trans)
mtl_results_trimmed <- mtl_results %>% select(-lambda.1, -lambda.2)
mtl_results_trimmed[ ,2:4] <- apply(mtl_results_trimmed[ ,2:4], 2, as.double)
mtl_results_trimmed$method <- factor(mtl_results_trimmed$method, levels = c("PLR", "RF", "SVM", "MTL"))
mtl_results_trimmed$transformation <- factor(mtl_results_trimmed$transformation, levels = c("Rank", "TSPs")) 
mtl_results_trimmed
```

#### Figure 4
#### Panel (A)

We compare the accuracies of the MTL predictions. We put them side by side with those of the random forest predictions.

``` {r concatenate_data} 
rf_results <- as.tibble(summary_table[which(summary_table$method == "RF" & summary_table$strategy == "Combined"), ]) %>% select(-strategy)
colnames(rf_results)[1] <- "testing.set"
concatenated_df <- bind_rows(mtl_results_trimmed, rf_results)
```

``` {r pred_accu_mtl}
ggplot(data = concatenated_df, aes(x = transformation, y = accuracy, fill = transformation)) +
  geom_boxplot(alpha = 0.8, width = 0.45) +
  ggtitle("Comparison of Prediction Accuracy",
          subtitle = "for the MTL method") +
  xlab("Transformation") +
  ylab("Accuracy") +
  theme_light() + facet_grid(. ~ method) +
  theme(axis.text.x = element_text(vjust = 0.5)) +
  scale_fill_manual(values = c("#E69F00", "#56B4E9"), 
                    name = "Transformation")
```

#### Panel (B)

``` {r roc_plot_mtl}
prediction_vec_mtl_rt <- as.vector(mtl_rt_preds[[1]][[1]])
prediction_vec_mtl_tsps <- as.vector(mtl_tsps_preds[[1]][[1]])

for(i in 2:num_studies) {
  prediction_vec_mtl_rt <- c(prediction_vec_mtl_rt, mtl_rt_preds[[i]][[1]])
  prediction_vec_mtl_tsps <- c(prediction_vec_mtl_tsps, mtl_tsps_preds[[i]][[1]])
}

roc2 <- plot.roc(truth_vec_combined, prediction_vec_mtl_rt,
                 main =  "ROC Curves for Predictions \nMTL",
                 col = "#E69F00")

lineobj2 <- lines.roc(truth_vec_combined, prediction_vec_mtl_tsps,
                     #smooth = TRUE,
                     col = "#56B4E9")

legend("bottomright", legend = c("Rank", "TSPs"), col = c("#E69F00", "#56B4E9"), lwd = 2, title = "Transformation")

```

#### Supplementary Figures
```{r pred_accu_method, echo = FALSE}
ggplot(data = results_tibble, aes(x = method, y = accuracy, fill = method)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Accuracy", subtitle = "by learning method") +
  xlab("Method") +
  ylab("Accuracy") +
  theme_classic() +
  scale_fill_discrete(name = "Method")
```

```{r pred_accu_transoformation, echo = FALSE}
ggplot(data = results_tibble, aes(x = transformation, y = accuracy, fill = transformation)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Accuracy", subtitle = "by transformation method") +
  xlab("Transformation") +
  ylab("Accuracy") +
  theme_classic() +
  scale_fill_discrete(name = "Transformation")
```

```{r pred_accu_strategy, echo = FALSE}
ggplot(data = results_tibble, aes(x = strategy, y = accuracy, fill = strategy)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Accuracy", subtitle = "by learning strategy") +
  xlab("Strategy") +
  ylab("Accuracy") +
  theme_classic() +
  scale_fill_discrete(name = "Strategy")
```

### Prediction Sensitivity

```{r pred_sensitvity, echo = FALSE}
ggplot(data = results_tibble, aes(x = interaction(transformation, strategy, sep = "-"), y = accuracy, col = interaction(transformation, strategy, sep = "-"))) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Senstivity") +
  xlab("Tranformation-Strategy") +
  ylab("Sensitivity") +
  theme_classic() + facet_grid(. ~ method) +
  theme(axis.text.x = element_text(vjust = 0.5, angle = 90)) + 
  scale_color_discrete(name = "Trans/Strategy")
```

```{r pred_sensitvity_method, echo = FALSE}
ggplot(data = results_tibble, aes(x = method, y = sensitivity, fill = method)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Senstivity", subtitle = "by learning method") +
  xlab("Method") +
  ylab("Sensitivity") +
  theme_classic() + 
  scale_fill_discrete(name = "Method") 
```

```{r pred_sensitvity_transformation, echo = FALSE}
ggplot(data = results_tibble, aes(x = transformation, y = sensitivity, fill = transformation)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Senstivity", subtitle = "by transformation method") +
  xlab("Transformation Method") +
  ylab("Sensitivity") +
  theme_classic() + 
  scale_fill_discrete(name = "Method") 
```


```{r pred_sensitvity_strategy, echo = FALSE}
ggplot(data = results_tibble, aes(x = strategy, y = sensitivity, fill = strategy)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Senstivity", subtitle = "by learning strategy") +
  xlab("Learning Strategy") +
  ylab("Sensitivity") +
  theme_classic() + 
  scale_fill_discrete(name = "Strategy") 
```

### Prediction Specificity

```{r pred_specificity, echo = FALSE}
ggplot(data = results_tibble, aes(x = interaction(transformation, strategy, sep = '-'), y = specificity, fill = interaction(transformation, strategy, sep = '-'))) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Specificity") +
  xlab("Transformation/Strategy") +
  ylab("Specificity") +
  theme_classic() + facet_grid(. ~ method) +
  theme(axis.text.x = element_text(vjust = 0.5, angle = 90)) + 
  scale_fill_discrete(name = "Trans/Strategy") 
```

```{r pred_specificity_method, echo = FALSE}
ggplot(data = results_tibble, aes(x = method, y = specificity, fill = method)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Specificity", subtitle = "by learning method") +
  xlab("Method") +
  ylab("Specificity") +
  theme_classic() +
  scale_fill_discrete(name = "Method") 
```

```{r pred_specificity_transformation, echo = FALSE}
ggplot(data = results_tibble, aes(x = transformation, y = specificity, fill = transformation)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Specificity", subtitle = "by transformation method") +
  xlab("Transformation Method") +
  ylab("Specificity") +
  theme_classic() +
  scale_fill_discrete(name = "Transformation Method") 
```

```{r pred_specificity_strategy, echo = FALSE}
ggplot(data = results_tibble, aes(x = strategy, y = specificity, fill = strategy)) +
  geom_boxplot(alpha = 0.8, width = 0.25) +
  ggtitle("Comparison of Prediction Specificity", subtitle = "by learning strategy") +
  xlab("Learning Strategy") +
  ylab("Specificity") +
  theme_classic() +
  scale_fill_manual(values = c("#E69F00", "#56B4E9"), name = "Learning Strategy")
```













