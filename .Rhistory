studies.names[i],
"SVM",
signif(accu, digits = 4),
signif(sen, digits = 4),
signif(spe, digits = 4))
}
print(learning.results, n = 2*length(studies)^2)
roc.data <- learning.results[learning.results$validation.set == "Aguirre-Seq"]
roc.data <- learning.results[learning.results$validation.set == "Aguirre-Seq", ]
add_column(roc.data,false.positive = 1 - spe)
roc.data
add_column(roc.data,false.positive = 1 - specificity)
add_column(roc.data,false.positive = 1 - learning.results$specificity)
learning.results$specificity
1 - learning.results$specificity
rep(1, length(learning.results$specificity)) - learning.results$specificity
add_column(roc.data,false.positive = rep(1, length(learning.results$specificity)))
roc.data
add_column(roc.data, false.positive = rep(1, length(roc.data$specificity)))
roc.data
roc.data <- add_column(roc.data, false.positive = rep(1, length(roc.data$specificity)))
roc.data
roc.data$false.positive <- roc.data$false.positive - roc.data$specificity
as.double("10")
for (i in 1:len) {
studies.min.1 <- studies[-i]
studies.names.min.1 <- studies.names[-i]
validation.set <- studies[[i]][ ,1:df.length]
truth <- studies[[i]]$cluster # The truth vector
# Run the RF (with 1500 trees) and SVM on one dataset, and validate on studies[i]
for (j in 1:length(studies.min.1)) {
learning.set <- studies.min.1[[j]]
# Random Forest
rf <- ranger::ranger(cluster~., data = learning.set, num.trees = 1500)
pred <- predict(rf, validation.set)
confusion.mat <- confusionMatrix(data = pred$predictions,
reference = truth)
accu <- confusion.mat$overall[["Accuracy"]]
sen <- confusion.mat$byClass[["Sensitivity"]]
spe <- confusion.mat$byClass[["Specificity"]]
learning.results[10*(i - 1) + 2*j - 1, ] <- c(studies.names.min.1[j],
studies.names[i],
"random forest",
as.double(signif(accu, digits = 4)),
as.double(signif(sen, digits = 4)),
as.double(signif(spe, digits = 4)))
# Supporting Vector Machine
supp.vec <- svm(cluster~., data = learning.set)
pred <- predict(supp.vec, validation.set)
confusion.mat <- confusionMatrix(data = pred,
reference = truth)
accu <- confusion.mat$overall[["Accuracy"]]
sen <- confusion.mat$byClass[["Sensitivity"]]
spe <- confusion.mat$byClass[["Specificity"]]
learning.results[10*(i - 1) + 2*j, ] <- c(studies.names.min.1[j],
studies.names[i],
"SVM",
as.double(signif(accu, digits = 4)),
as.double(signif(sen, digits = 4)),
as.double(signif(spe, digits = 4)))
}
# Run the RF and SVM on combined datasets
learning.set <- studies.min.1[[1]]
for (k in 1:(length(studies.min.1)-1)){
learning.set <- rbind(learning.set, studies.min.1[[1 + k]])
}
# Random Forest
rf <- ranger::ranger(cluster~., data = learning.set, num.trees = 1500)
pred <- predict(rf, validation.set)
confusion.mat <- confusionMatrix(data = pred$predictions,
reference = truth)
accu <- confusion.mat$overall[["Accuracy"]]
sen <- confusion.mat$byClass[["Sensitivity"]]
spe <- confusion.mat$byClass[["Specificity"]]
learning.results[10*i - 1, ] <- c(paste("comb. minus", studies.names[i],
sep = " "),
studies.names[i],
"random forest",
as.double(signif(accu, digits = 4)),
as.double(signif(sen, digits = 4)),
as.double(signif(spe, digits = 4)))
# Supporting Vector Machine
supp.vec <- svm(cluster~., data = learning.set)
pred <- predict(supp.vec, validation.set)
confusion.mat <- confusionMatrix(data = pred,
reference = truth)
accu <- confusion.mat$overall[["Accuracy"]]
sen <- confusion.mat$byClass[["Sensitivity"]]
spe <- confusion.mat$byClass[["Specificity"]]
learning.results[10*i, ] <- c(paste("comb. minus", studies.names[i],
sep = " "),
studies.names[i],
"SVM",
as.double(signif(accu, digits = 4)),
as.double(signif(sen, digits = 4)),
as.double(signif(spe, digits = 4)))
}
print(learning.results, n = 2*length(studies)^2)
roc.data$accuracy <- as.double(roc.data$accuracy)
roc.data
roc.data$sensitivity <- as.double(roc.data$sensitivity)
roc.data$specificity <- as.double(roc.data$specificity)
roc.data <- add_column(roc.data, false.positive = rep(1, length(roc.data$specificity)))
# Convert characters to doubles
roc.data <- learning.results[learning.results$validation.set == "Aguirre-Seq", ]
roc.data$accuracy <- as.double(roc.data$accuracy)
roc.data$sensitivity <- as.double(roc.data$sensitivity)
roc.data$specificity <- as.double(roc.data$specificity)
roc.data <- add_column(roc.data, false.positive = rep(1, length(roc.data$specificity)))
roc.data$false.positive <- roc.data$false.positive - roc.data$specificity
# Plot the roc curve
ggplot(aes(x = false.positive, y = sensitivity)) +
geom_point()
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point()
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point() +
geom_line(a = 1, b = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point() +
geom_abline(a = 1, b = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point() +
geom_abline(slope = 1, intercept = 0)
rep("Combined", 2))
roc.data <- add_column(roc.data, Type = rbind(rep("Single", 2*(length(studies) - 1)),
rep("Combined", 2)))
roc.data <- add_column(roc.data, Type = rbind(t(rep("Single", 2*(length(studies) - 1))),
t(rep("Combined", 2))))
)
roc.data <- add_column(roc.data, Type = rbind(t(rep("Single", 2*(length(studies) - 1)))
roc.data <- add_column(roc.data, Type = t(rep("Single", 2*(length(studies))))
a <- rbind(t(rep("Single",8)), t(rep("Combined", 10)))
t(rep("Single",8))
a <- rbind(rep("Single",8), rep("Combined", 10))
rep("Single",8)
a <- c(rep("Single",8), rep("Combined", 10))
a
t(a)
t(t(a))
# Add a column for learning set
learning.type <- c(rep("Single", 2*(length(studies) - 1))), rep("Combined", 2))
# Add a column for learning set
learning.type <- c(rep("Single", 8), rep("Combined", 2))
# Add a column for learning set
learning.type <- c(rep("Single", 2*(length(studies) - 1))), rep("Combined", 2))
# Add a column for learning set
learning.type <- c(rep("Single", 2*(length(studies) - 1)), rep("Combined", 2))
learning.type <- t(t(learning.type))
roc.data <- add_column(roc.data, Type = learning.type)
learning.type
roc.data <- add_column(roc.data, Type = as.vector(learning.type))
roc.data
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point(shape = type) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point(shape = Type) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point(shape = roc.data$Type) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point(shape = roc.data$Type, size = 2.5) +
geom_abline(slope = 1, intercept = 0)
# Add a column for learning set
learning.type <- c(rep(rep("Single", 2*(length(studies) - 1)), rep("Combined", 2), 5))
# Convert characters to doubles
roc.data <- learning.results
roc.data$accuracy <- as.double(roc.data$accuracy)
roc.data$sensitivity <- as.double(roc.data$sensitivity)
roc.data$specificity <- as.double(roc.data$specificity)
# Add a column for learning set
learning.type <- c(rep(rep("Single", 2*(length(studies) - 1)), rep("Combined", 2), 5))
learning.type <- t(t(learning.type))
roc.data <- add_column(roc.data, Type = as.vector(learning.type))
learning.type
# Add a column for learning set
learning.type <- c(rep("Single", 2*(length(studies) - 1)), rep("Combined", 2))
learning.type <- rep(learning.type, 5)
learning.2type
learning.type
learning.type <- t(t(learning.type))
roc.data <- add_column(roc.data, Type = as.vector(learning.type))
# Add a column for false positive
roc.data <- add_column(roc.data, false.positive = rep(1, length(roc.data$specificity)))
roc.data$false.positive <- roc.data$false.positive - roc.data$specificity
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity)) +
geom_point(col = roc.data$validation.set, shape = roc.data$Type, size = 2.5) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity), col = validation.set, shape = Type) +
geom_point(size = 2.5) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity), col = validation.set, shape = Type) +
geom_point(size = 1) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity), shape = roc.data$Type) +
geom_point(size = 1) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity), col = roc.data$Type) +
geom_point(size = 1) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point(size = 1) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point(size = 1.5) +
geom_abline(slope = 1, intercept = 0)
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type, size = method)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve for learning results")
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = c(method, Type))) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve for learning results")
ggtitle("ROC Curve for learning results")
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = method) +
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = method)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve for learning results")
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = method)) +
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = method)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve for learning results")
theme_classic()
# Plot the roc curve
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = method)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Methods") +
xlab("1 - Specificity") +
ylab("Sensityvity") +
theme_classic()
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Training Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic()
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Training Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid(validation.set ~ .)
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Training Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid(validation.set ~ ., rows = 2, cols = 3)
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Training Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( ~ validation.set)
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Training Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( . ~ Type)
# Plot out the accuracy
ggplot(data = roc.data, aes(x = Type, y = accuracy, col = validation.set)) +
geom_boxplot() +
geom_jitter() +
theme_classic() + facet_grid( . ~ validation.set)
# Plot out the accuracy
ggplot(data = roc.data, aes(x = Type, y = accuracy, fill = validation.set)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
theme_classic() + facet_grid( . ~ validation.set)
# Separate validation set type
is.Moffitt <- roc.data$validation.set == "Moffitt Arrays"
# Convert characters to doubles
roc.data <- learning.results
roc.data$accuracy <- as.double(roc.data$accuracy)
roc.data$sensitivity <- as.double(roc.data$sensitivity)
roc.data$specificity <- as.double(roc.data$specificity)
# Add a column for learning set
learning.type <- c(rep("single", 2*(length(studies) - 1)), rep("combined", 2))
learning.type <- rep(learning.type, 5)
learning.type <- t(t(learning.type))
learning.type <- factor(learning.type, levels = c("single", "combined"))
roc.data <- add_column(roc.data, Type = as.vector(learning.type))
# Add a column for false positive
roc.data <- add_column(roc.data, false.positive = rep(1, length(roc.data$specificity)))
roc.data$false.positive <- roc.data$false.positive - roc.data$specificity
# Separate validation set type
is.Moffitt <- roc.data$validation.set == "Moffitt Arrays"
roc.data <- add_column(roc.data, validation.set.type = rep("NGS", length(roc.data$specificity)))
roc.data$validation.set.type[is.Moffitt] <- "microarrays"
# Plot the roc curves
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = method)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Methods") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic()
# Plot the roc curves
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = method)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Methods") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( . ~ method)
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Studies of Validation Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( . ~ validation.set.type)
roc.data$validation.set.type <- factor(roc.data$validation.set.type, levels = c("NGS", "microarrays"))
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = Type)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Studies of Validation Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( . ~ validation.set.type)
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Learning Methods Types of Studies of Validation Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( Type ~ validation.set.type)
# Plot out the accuracy
ggplot(data = roc.data, aes(x = Type, y = accuracy, fill = validation.set)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
theme_classic() + facet_grid( . ~ validation.set)
# Plot out the accuracy
ggplot(data = roc.data, aes(x = Type, y = accuracy, fill = validation.set)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy Between Learning Methods") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ validation.set)
# Plot out the accuracy
ggplot(data = roc.data, aes(x = Type, y = accuracy, fill = validation.set)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy Between Learning Methods") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ validation.set) +
theme(axis.text.x = element_text(angle = 15))
# Plot out the accuracy
ggplot(data = roc.data, aes(x = Type, y = accuracy, fill = validation.set)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy Between Learning Methods") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ validation.set) +
theme(axis.text.x = element_text(vjust = 0.5, angle = 15))
ggplot(data = roc.data, aes(x = validation.set.type, y = accuracy, fill = validation.set.type)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy Between Types of Studies of Validation Sets") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ Type) +
theme(axis.text.x = element_text(vjust = 0.5, angle = 15))
ggplot(data = roc.data, aes(x = validation.set.type, y = accuracy, fill = validation.set.type)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy Between Types of Studies of Validation Sets") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ Type) +
theme(axis.text.x = element_text(vjust = 0.5))
ggplot(data = roc.data, aes(x = validation.set.type, y = accuracy, fill = validation.set.type)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy", subtitle = "Between Types of Studies of Validation Sets") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ Type) +
theme(axis.text.x = element_text(vjust = 0.5))
ggplot(data = roc.data, aes(x = validation.set.type, y = accuracy, fill = validation.set.type)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy", subtitle = "Between Types of Studies of Validation Sets") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ Type) +
theme(axis.text.x = element_text(vjust = 0.5)) +
scale_fill_discrete(name = "Type of \nStudies")
ggplot(data = roc.data, aes(x = validation.set.type, y = accuracy, fill = validation.set.type)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy", subtitle = "Between Types of Studies of Validation Sets") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ Type) +
theme(axis.text.x = element_text(vjust = 0.5)) +
scale_fill_discrete(name = "Type of Studies")
# Plot out the accuracy
ggplot(data = roc.data, aes(x = Type, y = accuracy, fill = validation.set)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy", subtitlle = "Between Learning Methods") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ validation.set) +
theme(axis.text.x = element_text(vjust = 0.5, angle = 15)) +
scale_fill_discrete(name = "Validation Dataset")
# Plot out the accuracy
ggplot(data = roc.data, aes(x = Type, y = accuracy, fill = validation.set)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy", subtitle = "Between Learning Methods") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid( . ~ validation.set) +
theme(axis.text.x = element_text(vjust = 0.5, angle = 15)) +
scale_fill_discrete(name = "Validation Dataset")
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Learning Methods Types of Studies of Validation Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( Type ~ validation.set.type) +
scale_fill_discrete(name = "Validation Dataset")
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Learning Methods Types of Studies of Validation Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( Type ~ validation.set.type) +
scale_col_discrete(name = "Validation Dataset")
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Learning Methods Types of Studies of Validation Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( Type ~ validation.set.type) +
scale_color_discrete(name = "Validation Dataset")
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Training Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( . ~ Type) +
scale_color_discrete(name = "Type of Learning \nDataset")
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Types of Training Sets") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( . ~ Type) +
scale_color_discrete(name = "Validation Dataset")
# Plot the roc curves
ggplot(data = roc.data, aes(x = false.positive, y = sensitivity, col = validation.set, shape = method)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
ggtitle("ROC Curve For Learning Results", subtitle = "Comparison Between Methods") +
xlab("1 - Specificity") +
ylab("Sensitivity") +
theme_classic() + facet_grid( . ~ method) +
scale_color_discrete(name = "Validation Dataset") +
scale_shape_discrete(name = "Learning Method")
ggplot(data = roc.data, aes(x = Type, y = accuracy, fill = validation.set)) +
geom_boxplot(alpha = 0.5) +
geom_jitter() +
ggtitle("Comparison of Prediction Accuracy", subtitle = "Between Types of Training Sets And Learning Methods") +
xlab("Learning Method") +
ylab("Accuracy") +
theme_classic() + facet_grid(method ~ validation.set) +
theme(axis.text.x = element_text(vjust = 0.5, angle = 15)) +
scale_fill_discrete(name = "Validation Dataset")
